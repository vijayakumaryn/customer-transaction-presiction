import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.metrics import roc_curve, roc_auc_score
import lightgbm as lgb
import timeit
import time

# Load the customer transaction dataset (train set) into a DataFrame
# The dataset likely contains features related to customer transactions and a target variable indicating transaction/no-transaction
df = pd.read_csv("D:/python project/PRCP-1003-CustTransPred/Data/train(1).csv")

# Display the first few rows of the dataset to inspect the structure and data
df.head()

# Get a statistical summary of the dataset (mean, std, min, max, etc.), useful for identifying outliers or data ranges
df.describe()

# Display the first row of the dataset to inspect individual values for quick validation
df.head(1)

# Drop 'ID_code' column as it is an identifier and does not provide useful information for prediction
df.drop(columns=['ID_code'], inplace=True)

# Check the dataset after dropping the 'ID_code' column
df.head()

# Display the last few rows of the dataset to check the overall structure and identify any anomalies
df.tail()

# Create a copy of the dataset to work on, ensuring the original dataset remains unchanged
df1 = df.copy()

# Check the shape (number of rows and columns) of the dataset, useful for understanding data size
df1.shape

# Get summary statistics of the dataset to analyze distributions, and ensure no drastic issues with data
df1.describe()

# Check the data types and non-null counts for each column to verify data integrity and look for missing data
df1.info()

# Visualize the distribution of the target variable ('transaction' or 'no transaction') to check for class imbalance
# Class imbalance is common in customer transaction prediction and may need to be addressed later
sns.countplot(x='target', data=df1)

# Check for missing values in the dataset to see if any data cleaning is required
print(df1.isnull().sum())

# Identify and display any duplicated rows in the dataset, as they can skew the model performance
dupli_row_col = df1[df1.duplicated(keep=False)]
dupli_row_col

# Split the dataset into features (X) and target variable (y)
# X contains all the feature columns related to customer behavior, while y is the target variable (transaction status)
x = df1.drop(columns=['target'])  # Drop 'target' from the features
y = df1['target']  # Set the target variable

# Standardize the feature values using StandardScaler
# Standardization is important as models like Logistic Regression can be sensitive to the scale of the input features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(x)  # Scale the feature values to have mean=0 and std=1

# Convert the scaled features back into a DataFrame with original column names for easier interpretation
X = pd.DataFrame(X_scaled, columns=x.columns)

# Get summary statistics of the scaled features to ensure proper standardization
X.describe()

# Compute the correlation matrix to examine the relationships between features and the target variable
# This helps in understanding which features are most correlated with the likelihood of a transaction
corr_mat = df1.corr()

# Sort the correlations with respect to the target variable ('target') to identify the most influential features
correlation_with_target = corr_mat['target'].sort_values(ascending=False)
correlation_with_target

# Plot a heatmap of the correlation matrix to visually understand the relationships between features
# This can guide feature selection or engineering steps
plt.figure(figsize=(20, 25))  # Set figure size to make the heatmap readable
sns.heatmap(corr_mat, annot=True, cmap='coolwarm', linewidths=.5)  # Use 'coolwarm' for better visual contrast
plt.title("Correlation Heatmap")  # Title for the heatmap
plt.show()

# Split the dataset into training and testing sets
# 70% of the data is used for training the model, and 30% is kept for evaluating model performance
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Print the shapes of the training and testing sets to ensure the split has been done correctly
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

# Initialize a Logistic Regression model for binary classification (transaction vs no-transaction)
# Logistic Regression is a commonly used baseline model for classification problems
lr_model = LogisticRegression()

# Train the Logistic Regression model on the training data
lr_model.fit(X_train, y_train)

# Use the trained model to make predictions on the test set
lr_pred = lr_model.predict(X_test)

# Evaluate the model performance using accuracy metric
# Accuracy is useful for getting an overall sense of model performance but may not be sufficient if the dataset is imbalanced
lr_accuracy = accuracy_score(y_test, lr_pred)
print("Accuracy:", lr_accuracy)

# Calculate precision: measures how many of the predicted positive cases were actually positive
# Useful in cases where false positives are costly
lr_precision = precision_score(y_test, lr_pred)
print("Precision:", lr_precision)

# Calculate recall: measures how many actual positive cases were correctly identified
# Important when false negatives (missed transactions) are costly
lr_recall = recall_score(y_test, lr_pred)
print("Recall:", lr_recall)

# Calculate F1 score: harmonic mean of precision and recall, useful when you need a balance between precision and recall
lr_f1_score = f1_score(y_test, lr_pred)
print("F1 Score:", lr_f1_score)

# Print the full classification report, which includes precision, recall, F1-score, and support for both classes
# This helps evaluate how well the model is predicting both the transaction and no-transaction classes
print("\n", classification_report(y_test, lr_pred))

# Compute the confusion matrix to compare predicted vs actual values
# This matrix shows the counts of true positives, true negatives, false positives, and false negatives
lr_con_mat = confusion_matrix(y_test, lr_pred)

# Visualize the confusion matrix using a heatmap for better understanding
plt.figure(figsize=(6, 6))  # Set the size of the confusion matrix plot
custom_cmap = sns.color_palette("YlGnBu")  # Use a color palette for the heatmap
sns.heatmap(lr_con_mat, annot=True, fmt='d', cmap=custom_cmap, xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.xlabel('Predicted')  # Label for the x-axis representing predicted values
plt.ylabel('True')  # Label for the y-axis representing actual values
plt.title('Confusion Matrix')  # Title for the confusion matrix plot
plt.show()

# Next steps could involve trying more advanced models like LightGBM for better prediction performance
